{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FxZjGWAsovq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def show_images(image_dir):\n",
        "    folder_name = os.path.basename(image_dir)\n",
        "    # Get the list of image files in the directory\n",
        "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(1, 2, dpi=200)\n",
        "\n",
        "    # Loop through the image files and display them in subplots\n",
        "    for i, image_file in enumerate(image_files[2:4]):  # Display only the first two images\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        image = plt.imread(image_path)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(str(folder_name))\n",
        "\n",
        "    # Adjust the spacing between subplots\n",
        "    plt.subplots_adjust(wspace=0.1)\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "image_directory = \"/content/drive/MyDrive/Kidney data/Grade0/Grade1/Grade2/Gerade3/Grade4\"\n",
        "show_images(image_directory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import log_loss,cohen_kappa_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "LIKgvhOes9ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the path to the dataset folder\n",
        "dataset_path = \"/content/drive/MyDrive/Kidney data\"\n",
        "\n",
        "# Define the list of label folders in the dataset folder\n",
        "label_folders = [\"Grade0\", \"Grade1\",\"Grade2\",\"Grade3\",\"Grade4\"]\n",
        "\n",
        "# Define the size of the input images\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "# Define an empty list to store the images and their labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Loop over the label folders in the dataset folder\n",
        "for label_folder in label_folders:\n",
        "    # Define the path to the label folder\n",
        "    label_path = os.path.join(dataset_path, label_folder)\n",
        "    # Loop over the images in the label folder\n",
        "    for img_name in os.listdir(label_path):\n",
        "        # Define the path to the image\n",
        "        img_path = os.path.join(label_path, img_name)\n",
        "        # Load the image and resize it to the desired size\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (img_height, img_width))\n",
        "        # Append the image and its label to the data and labels lists\n",
        "        data.append(img)\n",
        "        labels.append(label_folder)\n",
        "\n",
        "# Convert the data and labels lists to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "# labels = to_categorical(labels)\n",
        "\n",
        "# Print the shape of the data and labels arrays\n",
        "print(\"Data shape:\", data.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ],
      "metadata": {
        "id": "X0c-_uNXtbL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Get the unique string values\n",
        "unique_values = np.unique(labels)\n",
        "\n",
        "# Create a mapping dictionary\n",
        "mapping = {value: index for index, value in enumerate(unique_values)}\n",
        "\n",
        "# Map the string values to numbers\n",
        "mapped_arr = np.array([mapping[value] for value in labels])\n",
        "\n",
        "print(\"Original array:\", labels)\n",
        "print(\"Mapped array:\", mapped_arr)\n",
        "print(\"Mapping dictionary:\", mapping)\n"
      ],
      "metadata": {
        "id": "CXdk5wZYtgN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN building"
      ],
      "metadata": {
        "id": "mZaMg8AeuFG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        # Convolutional layers\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "        # Dense layers\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='sigmoid'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "# Define input shape and number of classes\n",
        "input_shape = (256, 256, 3)  # Assuming input images are 128x128 RGB\n",
        "num_classes = 5  # Example with 10 classes\n",
        "\n",
        "# Create the CNN model\n",
        "model = create_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gh8bjcl0tjnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train, Y_train, epochs=10,validation_split=0.1 )"
      ],
      "metadata": {
        "id": "XbGKexAItoIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graph(history,string):\n",
        "\n",
        "    plt.plot(history.history[string],label='training '+string)\n",
        "    plt.plot(history.history['val_'+string],label='validation '+string)\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.title(string+' vs epochs')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3jaMbV9OtrFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(history,'loss')"
      ],
      "metadata": {
        "id": "bAJvXXg7txnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graph(history,'accuracy')"
      ],
      "metadata": {
        "id": "z5afesYmt0ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, Y_train)\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "lZCDKrVvt1hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Convert ypred to multiclass format if it's in multilabel-indicator format\n",
        "if ypred.ndim == 2:  # Check if ypred is a 2D array (multilabel-indicator)\n",
        "    ypred = np.argmax(ypred, axis=1)  # Convert to multiclass\n",
        "\n",
        "print(classification_report(Y_test, ypred))\n",
        "cf_matrix = confusion_matrix(Y_test, ypred)\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "id": "2QXgPEVLt1xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Feature extraction spatial using CNN"
      ],
      "metadata": {
        "id": "vPWepcezuNWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "\n",
        "# Define a custom CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1000, activation='softmax')  # Adjust output classes according to your task\n",
        "])\n",
        "\n",
        "# Build the model\n",
        "model.build(input_shape=(None,) + input_shape)\n"
      ],
      "metadata": {
        "id": "65hGjdx1t1_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = model.predict(data)"
      ],
      "metadata": {
        "id": "LM1tf0Oxt2Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv('')\n",
        "df1['label']=labels\n",
        "df1"
      ],
      "metadata": {
        "id": "Cnj_9WVtuZuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "le=preprocessing.LabelEncoder()\n",
        "df1['label']=le.fit_transform(df1['label'])\n",
        "df1['label'].value_counts()"
      ],
      "metadata": {
        "id": "JH6UIjLYufGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as tkr\n",
        "def func(x, pos):  # formatter function takes tick label and tick position\n",
        "    s = '%d' % x\n",
        "    groups = []\n",
        "    while s and s[-1].isdigit():\n",
        "        groups.append(s[-3:])\n",
        "        s = s[:-3]\n",
        "    return s + ','.join(reversed(groups))\n",
        "\n",
        "y_format = tkr.FuncFormatter(func)  # make formatter\n",
        "plt.figure(figsize=(6,4), dpi = 100)\n",
        "p=sns.countplot(x='label',data= df1 )\n",
        "p.yaxis.set_major_formatter(y_format)\n",
        "p.tick_params(labelsize=13)\n",
        "# plt.xticks(rotation = 50)\n",
        "plt.xlabel(\"Class\",fontsize=12)\n",
        "plt.ylabel(\"Count\",fontsize=12)\n",
        "# plt.savefig('barchart.pdf',dpi=100,bbox_inches = 'tight')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ibLGH86xuhqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result with spatial features"
      ],
      "metadata": {
        "id": "Bq-XhpQCuuL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "clf = KNeighborsClassifier(n_neighbors=2)\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "dtP3=clf.predict(X_test)\n",
        "print('accuracy score',accuracy_score(Y_test,dtP3))\n",
        "print('error rate:',1-accuracy_score(Y_test,dtP3))\n",
        "print(classification_report(Y_test,dtP3))\n",
        "# kf = KFold(n_splits=10, shuffle=True)\n",
        "# clf = KNeighborsClassifier(n_neighbors=2)\n",
        "# score = cross_val_score(clf, result, y, cv= kf, scoring=\"accuracy\")\n",
        "# print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "cf_matrix=confusion_matrix(Y_test,dtP3)\n",
        "cf_matrix"
      ],
      "metadata": {
        "id": "8JZGZNN4uok1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "print(\"RF\")\n",
        "clf=RandomForestClassifier(max_depth=300, random_state=0,n_estimators=300)\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "dtP3=clf.predict(X_test)\n",
        "print('error rate:',1-accuracy_score(Y_test,dtP3))\n",
        "print(classification_report(Y_test,dtP3))\n",
        "print('accuracy score',round(accuracy_score(Y_test,dtP3),2))\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "clf=RandomForestClassifier(max_depth=300, random_state=0,n_estimators=300)\n",
        "# Assuming 'result' should have been 'x', the feature matrix\n",
        "score = cross_val_score(clf, x, y, cv= kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "cf_matrix=confusion_matrix(Y_test,dtP3)\n",
        "cf_matrix"
      ],
      "metadata": {
        "id": "MIRxG1Wjuooa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import time\n",
        "\n",
        "# Inject noise into the data\n",
        "noise_factor = 0.5  # Adjust this to control the amount of noise\n",
        "X_train_noisy = X_train + noise_factor * np.random.normal(size=X_train.shape)\n",
        "X_test_noisy = X_test + noise_factor * np.random.normal(size=X_test.shape)\n",
        "\n",
        "# Initialize the Gaussian Naive Bayes model\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Measure the training time\n",
        "start = time.time()\n",
        "clf.fit(X_train_noisy, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "# Predict the test set results with noisy data\n",
        "dtP3 = clf.predict(X_test_noisy)\n",
        "\n",
        "# Output the accuracy and error rate\n",
        "print('Accuracy score:', accuracy_score(Y_test, dtP3))\n",
        "print('Error rate:', 1 - accuracy_score(Y_test, dtP3))\n",
        "\n",
        "# Output the classification report\n",
        "print(classification_report(Y_test, dtP3))\n",
        "\n",
        "# Perform k-fold cross-validation with noisy data\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "score = cross_val_score(clf, X_train_noisy, Y_train, cv=kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cf_matrix = confusion_matrix(Y_test, dtP3)\n",
        "cf_matrix\n"
      ],
      "metadata": {
        "id": "zk4ke1SBuorf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "print(\"SGD\")\n",
        "\n",
        "# Initialize the SGDClassifier\n",
        "clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=0)\n",
        "\n",
        "# Measure the training time\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "# Make predictions\n",
        "dtP3 = clf.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print('Error rate:', 1 - accuracy_score(Y_test, dtP3))\n",
        "print(classification_report(Y_test, dtP3))\n",
        "print('Accuracy score:', round(accuracy_score(Y_test, dtP3), 2))\n",
        "\n",
        "# Optionally perform cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "score = cross_val_score(clf, X_train, Y_train, cv=kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "\n",
        "# Confusion matrix\n",
        "cf_matrix = confusion_matrix(Y_test, dtP3)\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "id": "iuGMreZUu85q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble based prolistic feature Extraction"
      ],
      "metadata": {
        "id": "oyamjZMJvEWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Assuming x and y are your features and target variables\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "x_poly = poly.fit_transform(x)\n",
        "\n",
        "# Initialize and train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=30, random_state=0)\n",
        "rf_predictions = rf.fit(x_poly, y).predict_proba(x_poly)\n",
        "rf_df = pd.DataFrame(rf_predictions, columns=[f'Class_{i}' for i in range(rf_predictions.shape[1])])\n",
        "\n",
        "# Initialize and train Gaussian Naive Bayes\n",
        "gnb = GaussianNB()\n",
        "gnb_predictions = gnb.fit(x_poly, y).predict_proba(x_poly)\n",
        "gnb_df = pd.DataFrame(gnb_predictions, columns=[f'Class_{i}' for i in range(gnb_predictions.shape[1])])\n",
        "\n",
        "# Initialize and train Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000, random_state=0)\n",
        "lr_predictions = lr.fit(x_poly, y).predict_proba(x_poly)\n",
        "lr_df = pd.DataFrame(lr_predictions, columns=[f'Class_{i}' for i in range(lr_predictions.shape[1])])\n",
        "\n",
        "# Output the DataFrames for Random Forest, GNB, and LR predictions\n",
        "print(\"Random Forest Predictions:\")\n",
        "print(rf_df.head())\n",
        "\n",
        "print(\"Gaussian Naive Bayes Predictions:\")\n",
        "print(gnb_df.head())\n",
        "\n",
        "print(\"Logistic Regression Predictions:\")\n",
        "print(lr_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "KajrtXpkvIj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'lr_df' from the previous cell is what was intended as 'pl'\n",
        "result = pd.concat([lr_df,rf_df], axis=1).reindex(lr_df.index)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(result,y,test_size = 0.2,random_state=0,shuffle=True)\n",
        "# result.columns=['1','2','3','4']"
      ],
      "metadata": {
        "id": "JuM0mKm3vWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "enwfd1ZmvIn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "result with newly transfer feature set"
      ],
      "metadata": {
        "id": "tZ8FMkByvfNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "print(\"RF\")\n",
        "clf=RandomForestClassifier(max_depth=300, random_state=0,n_estimators=300)\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "dtP3=clf.predict(X_test)\n",
        "print('error rate:',1-accuracy_score(Y_test,dtP3))\n",
        "print(classification_report(Y_test,dtP3))\n",
        "print('accuracy score',accuracy_score(Y_test,dtP3))\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "clf=RandomForestClassifier(max_depth=300, random_state=0,n_estimators=300)\n",
        "score = cross_val_score(clf, result, y, cv= kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "cf_matrix=confusion_matrix(Y_test,dtP3)\n",
        "cf_matrix"
      ],
      "metadata": {
        "id": "9CrgSqH8vabm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "print(\"LR\")\n",
        "clf=LogisticRegression()\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "dtP3=clf.predict(X_test)\n",
        "print('error rate:',1-accuracy_score(Y_test,dtP3))\n",
        "print(classification_report(Y_test,dtP3))\n",
        "print('accuracy score',round(accuracy_score(Y_test,dtP3),2))\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "clf=LogisticRegression()\n",
        "score = cross_val_score(clf, result, y, cv= kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "cf_matrix=confusion_matrix(Y_test,dtP3)\n",
        "cf_matrix\n"
      ],
      "metadata": {
        "id": "QZ90RiZovaen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mport time\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "\n",
        "# Initialize the GaussianNB model\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Measure the training time\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "# Make predictions\n",
        "dtP3 = clf.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print('Accuracy score:', accuracy_score(Y_test, dtP3))\n",
        "print('Error rate:', 1 - accuracy_score(Y_test, dtP3))\n",
        "print(classification_report(Y_test, dtP3))\n",
        "\n",
        "# Optionally perform cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "score = cross_val_score(clf, X_train, Y_train, cv=kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "\n",
        "# Confusion matrix\n",
        "cf_matrix = confusion_matrix(Y_test, dtP3)\n",
        "print(cf_matrix)\n"
      ],
      "metadata": {
        "id": "G7aIU1knvoKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "print(\"SGD\")\n",
        "\n",
        "# Initialize the SGDClassifier\n",
        "clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=0)\n",
        "\n",
        "# Measure the training time\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "# Make predictions\n",
        "dtP3 = clf.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print('Error rate:', 1 - accuracy_score(Y_test, dtP3))\n",
        "print(classification_report(Y_test, dtP3))\n",
        "print('Accuracy score:', round(accuracy_score(Y_test, dtP3), 2))\n",
        "\n",
        "# Optionally perform cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "score = cross_val_score(clf, X_train, Y_train, cv=kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "\n",
        "# Confusion matrix\n",
        "cf_matrix = confusion_matrix(Y_test, dtP3)\n",
        "print(cf_matrix)\n"
      ],
      "metadata": {
        "id": "7bhs51XKvoX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import time\n",
        "\n",
        "# Initialize the Gaussian Naive Bayes model\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Measure the training time\n",
        "start = time.time()\n",
        "clf.fit(X_train, Y_train)\n",
        "stop = time.time()\n",
        "print(f\"Training time: {stop - start}s\")\n",
        "\n",
        "# Predict the test set results\n",
        "dtP3 = clf.predict(X_test)\n",
        "\n",
        "# Output the accuracy and error rate\n",
        "print('Accuracy score:', accuracy_score(Y_test, dtP3))\n",
        "print('Error rate:', 1 - accuracy_score(Y_test, dtP3))\n",
        "\n",
        "# Output the classification report\n",
        "print(classification_report(Y_test, dtP3))\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "score = cross_val_score(clf, result, y, cv=kf, scoring=\"accuracy\")\n",
        "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (score.mean(), score.std()))\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cf_matrix = confusion_matrix(Y_test, dtP3)\n",
        "cf_matrix\n"
      ],
      "metadata": {
        "id": "AhU48XPfvobd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8dSdgf9voeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrices for different models\n",
        "conf_matrices = {\n",
        "    \"GNB\": np.array([[ 7,  0,  0,  0,  0],\n",
        "                     [ 0,  8,  0,  1,  0],\n",
        "                     [ 0,  0, 11,  0,  0],\n",
        "                     [ 0,  0,  0, 16,  0],\n",
        "                     [ 0,  0,  0,  0, 13]]),\n",
        "\n",
        "    \"KNC\": np.array([[ 7,  0,  0,  0,  0],\n",
        "                     [ 0,  9,  0,  0,  0],\n",
        "                     [ 0,  0, 11,  0,  0],\n",
        "                     [ 0,  0,  0, 16,  0],\n",
        "                     [ 0,  0,  0,  0, 13]]),\n",
        "\n",
        "    \"SGD\": np.array([[ 7,  0,  0,  0,  0],\n",
        "                     [ 0,  9,  0,  0,  0],\n",
        "                     [ 0,  0, 11,  0,  0],\n",
        "                     [ 0,  0,  0, 16,  0],\n",
        "                     [ 0,  0,  0,  0, 13]]),\n",
        "\n",
        "    \"nB\": np.array([[ 7,  0,  0,  0,  0],\n",
        "                    [ 0,  8,  0,  1,  0],\n",
        "                    [ 0,  0, 11,  0,  0],\n",
        "                    [ 0,  0,  0, 16,  0],\n",
        "                    [ 0,  0,  0,  0, 13]]),\n",
        "\n",
        "    \"LR\": np.array([[ 7,  0,  0,  0,  0],\n",
        "                    [ 0,  9,  0,  0,  0],\n",
        "                    [ 0,  0, 11,  0,  0],\n",
        "                    [ 0,  0,  0, 16,  0],\n",
        "                    [ 0,  0,  0,  0, 13]]),\n",
        "\n",
        "    \"RF\": np.array([[ 7,  0,  0,  0,  0],\n",
        "                    [ 0,  9,  0,  0,  0],\n",
        "                    [ 0,  0, 11,  0,  0],\n",
        "                    [ 0,  0,  0, 16,  0],\n",
        "                    [ 0,  0,  0,  0, 13]])\n",
        "}\n",
        "\n",
        "# Plot heatmaps for each confusion matrix\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "for ax, (model_name, cf_matrix) in zip(axes.flatten(), conf_matrices.items()):\n",
        "    sns.heatmap(cf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
        "    ax.set_title(f'{model_name} Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    ax.set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aoLSCyYGvaiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mport hypertools as hyp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'result' is your feature matrix and 'y' is your label array\n",
        "# y could be [0, 1, 2, 3, 4] corresponding to the grades\n",
        "# Replace 'y' and 'result' with your actual data\n",
        "\n",
        "# Create a label mapping for the 5 classes (Grade 0 to Grade 4)\n",
        "label_mapping = {0: 'Grade 0', 1: 'Grade 1', 2: 'Grade 2', 3: 'Grade 3', 4: 'Grade 4'}\n",
        "# Use the 'y' variable instead of 'Labels'\n",
        "labels_mapped = [label_mapping[label] for label in y]\n",
        "\n",
        "# Visualize the feature space with hypertools\n",
        "plt.figure(figsize=(10, 5.5), dpi=200)\n",
        "hyp.plot(result, 'o', group=labels_mapped, legend=True, n_clusters=5, palette=\"deep\", azim=50)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iGJwyhXcvakw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0mgxlDbKvanj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rom sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "for images, labels in val:\n",
        "    predictions = hybrid_model.predict(images)\n",
        "    y_pred.extend(np.argmax(predictions, axis=1))\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_true, y_pred, target_names=['Class1', 'Class2', 'Class3', 'Class4', 'Class5'])  # Replace with your class labels\n",
        "print(report)"
      ],
      "metadata": {
        "id": "IZaUCbIUvaqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'test' is already defined and preprocessed as in the previous steps\n",
        "# Predict probabilities on the test data\n",
        "y_pred_prob = []\n",
        "y_true = []\n",
        "\n",
        "for images, labels in val:\n",
        "    predictions = hybrid_model.predict(images)\n",
        "    y_pred_prob.extend(predictions)\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "# Binarize the true labels for ROC calculation\n",
        "y_true_binarized = label_binarize(y_true, classes=[0, 1, 2, 3, 4])  # Adjust classes to your number of classes\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "n_classes = 5  # Number of classes\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], np.array(y_pred_prob)[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "plt.figure()\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2, label='Class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uuGruj0svatY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}